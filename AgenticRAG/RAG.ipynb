{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "264d7036-32a3-4fb5-8eab-363b94f07cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain langchain-community langchain-google-genai langchain-core langchain-text-splitters chromadb python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa3a0c73-a5fa-4c7f-acbf-d5cf9e162676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62eb298f-230d-4d10-92eb-b4206839f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load the laptop data\n",
    "loader = TextLoader(\"laptops_info.txt\")\n",
    "raw_docs = loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc50d673-3d2b-4c35-a469-b5d411e8e99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents:  5\n",
      "printing one of the document........\n",
      "page_content='3. ASUS TUF Gaming F15\n",
      "- Price: â‚¹79,990\n",
      "- CPU: Intel i5 11400H\n",
      "- GPU: NVIDIA RTX 3050 (4GB)\n",
      "- RAM: 16GB DDR4\n",
      "- Storage: 512GB SSD\n",
      "- Good for: Deep learning models, parallel processing\n",
      "- Comments: Rugged build, best performance for the price\n",
      "\n",
      "4. Acer Aspire 7\n",
      "- Price: â‚¹62,990\n",
      "- CPU: AMD Ryzen 5 5500U\n",
      "- GPU: NVIDIA GTX 1650\n",
      "- RAM: 8GB\n",
      "- Storage: 512GB SSD\n",
      "- Good for: Intro ML, data science\n",
      "- Comments: Value for money, limited by RAM/GPU' metadata={'source': 'laptops_info.txt'}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Split the documents into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(raw_docs)\n",
    "print(\"Total number of documents: \",len(docs))\n",
    "\n",
    "print(\"printing one of the document........\")\n",
    "print(docs[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fef7d4d0-0c11-415b-ae6f-119475536972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example embeddings........\n",
      "[0.05636945366859436, 0.004828543867915869, -0.07625909894704819, -0.023642510175704956, 0.053293220698833466]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Initialize the embedding model\n",
    "#Get an API key: \n",
    "# Head to https://ai.google.dev/gemini-api/docs/api-key to generate a Google AI API key. Paste in .env file\n",
    "# Embedding models: https://python.langchain.com/v0.1/docs/integrations/text_embedding/\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "import os\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "\n",
    "vector = embedding_model.embed_query(\"hello, world!\")\n",
    "\n",
    "#vector\n",
    "print(\"example embeddings........\")\n",
    "\n",
    "print(vector[:5])\n",
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5f39e96-d98c-429e-b284-196ab9314705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create Chroma vectorstore\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d83dc9f1-66f8-477b-afa1-963cb95f05e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Convert to retriever\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b56b5e07-a6a1-4fc9-ad47-ac133ee11524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 6: Run a query (RAG-style)\n",
    "query = \"Which laptop is best for machine learning under ₹80,000?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "print(len(retrieved_docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d3d8028-4dff-47ab-ba28-4483bb0cee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Retrieved Chunks:\n",
      "\n",
      "Chunk 1:\n",
      "# Laptop Buying Tips for AI/ML (2024)\n",
      "- Prefer 16GB RAM or more\n",
      "- Look for NVIDIA GPUs like GTX 1650, RTX 3050 or better\n",
      "- Avoid integrated graphics for training models\n",
      "- SSD preferred for fast data access\n",
      "- Ryzen 5, i5 H-series or better recommended\n",
      "\n",
      "Chunk 2:\n",
      "# Laptop Buying Tips for AI/ML (2024)\n",
      "- Prefer 16GB RAM or more\n",
      "- Look for NVIDIA GPUs like GTX 1650, RTX 3050 or better\n",
      "- Avoid integrated graphics for training models\n",
      "- SSD preferred for fast data access\n",
      "- Ryzen 5, i5 H-series or better recommended\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Print retrieved chunks\n",
    "print(\"\\nTop Retrieved Chunks:\")\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\nChunk {i+1}:\\n{doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d08aac-c676-47ce-8df2-d8d69c3567d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
